## 中间件

### Zookeeper

- ZAB协议（Zookeeper原子消息广播协议）
    - 事务编号Zxid是64位，低32位为处理的事务递增，高32位代表Leader周期epoch编号，在选主后递增并重置低32位
    - 两种模式：恢复模式（选主）、广播模式（同步）
- znode：树状目录结构。每个节点都可以存放数据，但上限为1M
- Znode四种类型：持久节点、临时节点、持久顺序节点、临时顺序节点
- Watcher机制：数据变更通知。工作机制：客户端注册watcher--服务端处理watcher--客户端回调watcher
- 服务器角色：Leader、Follower、Observer（用于提升集群非事务的处理能力，不参与投票）
- 数据同步：直接差异化同步、先回滚再差异化同步、仅回滚同步、全量同步
- 一些节点
    - 集群启动：恢复模式，leader选举（过半机器选举机制） + 数据同步
    - 消息写入：消息广播模式，leader采用2PC模式的过半写机制，给follower进行同步
    - 崩溃恢复：恢复模式，leader/follower宕机，只要剩余机器超过一半，集群宕机不超过一半的机器，就可以选举新的leader，数据同步
- 因为集群重选leader需要半数以上的得票，所以集群一般为奇数台。
- ZK是顺序一致性（不是强一致性，比最终一致性要好一些）

### Dubbo

- Dubbo是一个轻量级的分布式服务框架。RPC
- Apache Dubbo |ˈdʌbəʊ| 提供了六大核心能力：面向接口代理的高性能RPC调用，智能容错和负载均衡，服务自动注册和发现，高度可扩展能力，运行期流量调度，可视化的服务治理与运维。
- Dubbo Monitor实现原理：Consumer 端在发起调用之前会先走 filter 链; Provider 端在接收到请求时也是 先走 filter 链，然后才进行真正的业务逻辑处理。默认情况下，在 consumer 和 provider 的 filter 链中都会有
  Monitorfilter。MonitorFilter 向DubboMonitor 发送数据。
- Dubbo SPI 和 Java SPI 区别

    - JDK SPI：JDK 标准的 SPI 会一次性加载所有的扩展实现，如果有的扩展很耗时，又也没用上，就造成了资源浪费。无法实现只加载某个的实现。

    - Dubbo SPI：
        - 对 Dubbo 进行扩展，不需要改动 Dubbo 的源码
        - 延迟加载，可以一次只加载自己想要加载的扩展实现。
        - 增加了对扩展点 IOC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点。
        - Dubbo 的扩展机制能很好的支持第三方 IoC 容器，默认支持 Spring Bean。
- RPC框架的原理：
    - **客户端（服务消费端）** ：调用远程方法的一端。
    - **客户端 Stub（桩）** ： 这其实就是一代理类。代理类主要做的事情很简单，就是把你调用方法、类、方法参数等信息传递到服务端。
    - **网络传输** ： 网络传输就是你要把你调用的方法的信息比如说参数啊这些东西传输到服务端，然后服务端执行完之后再把返回结果通过网络传输给你传输回来。网络传输的实现方式有很多种比如最近基本的 Socket或者性能以及封装更加优秀的 Netty（推荐）。
    - **服务端 Stub（桩）** ：这个桩就不是代理类了。我觉得理解为桩实际不太好，大家注意一下就好。这里的服务端 Stub 实际指的就是接收到客户端执行方法的请求后，去指定对应的方法然后返回结果给客户端的类。
    - **服务端（服务提供端）** ：提供远程方法的一端。

- RPC过程
    - 服务消费端（client）以本地调用的方式调用远程服务；
    - 客户端 Stub（client stub） 接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体（序列化）：`RpcRequest`；
    - 客户端 Stub（client stub） 找到远程服务的地址，并将消息发送到服务提供端；
    - 服务端 Stub收到消息将消息反序列化为Java对象: `RpcRequest`；
    - 服务端 Stub根据`RpcRequest`中的类、方法、方法参数等信息调用本地的方法；
    - 服务端 Stub得到方法执行结果并将组装成能够进行网络传输的消息体：`RpcResponse`（序列化）发送至消费方；
    - 客户端 Stub（client stub）接收到消息并将消息反序列化为Java对象:`RpcResponse` ，这样也就得到了最终结果。

### Elasticsearch

- Elasticsearch 是一个分布式、可扩展、实时的搜索与数据分析引擎。 它能从项目一开始就赋予你的数据以搜索、分析和探索的能力，可用于实现全文搜索和实时数据统计。
- 倒排索引（Inverted index）：

  通俗解答方式：

    - 传统的我们的检索是通过文章，逐个遍历找到对应关键词的位置。
    - 而倒排索引，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表即为倒排索引。
    - 有了倒排索引，就能实现 o(1)时间复杂度的效率检索文章了，极大的提高了检索效率

  学术的解答方式:

    - 倒排索引，相反于一篇文章包含了哪些词，它从词出发，记载了这个词在哪些文档中出现过，由两部分组成——词典和倒排表。

  加分项:倒排索引的底层实现是基于:FST(Finite State Transducer)数据结构。 lucene 从 4+版本后开始大量使用的数据结构是 FST。FST 有两个优点:

  1、空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间;

  2、查询速度快。O(len(str))的查询时间复杂度。

- 选主：只有候选主节点(master:true)的节点才能成为主节点。 最小主节点数min_master_nodes。最少投票通过数量（discovery.zen.minimum_master_nodes）。得票需大于一半且有投自己。

- master 节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理;data 节点可以关闭 http 功能。

- ES索引文档：refresh阶段（Momery Buffer到Filesystem Cache，1s）、flush阶段（Filesystem Cache到磁盘，30min）。

  通过translog来保证数据的可靠性：写入时同步写translog，在刷盘成功时再清除，但translog默认也是有OS Cache，每隔5秒刷一次，所以可能导致数据丢失。

- ES更新和删除文档
    - 删除和更新也都是写操作，但是 Elasticsearch 中的文档是不可变的，因此不能被删除或者改动以展示其变更;
    - 磁盘上的每个段都有一个相应的.del 文件。当删除请求发送后，文档并没有真的被删除，而是在.del 文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del 文件中被标记为删除的文档将不会被写入新段。
    - 在新的文档被创建时，Elasticsearch 会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del 文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。
    - 更新从本质上讲是一个先删再增的过程
- ES搜索过程：query阶段（定位位置）、fetch阶段（取数据）；搜索会查询Filesystem Cache中的内容，但不搜索Memory Buffer，所以搜索是近实时的。
- 对ES，CPU更多的核心比更高的频率重要。内存至少8，但不要大于32G，heap size不要超过系统可用内存的一半。最好用SSD。要让 es 性能好，最佳的情况下，机器的内存，至少可以容纳你的总数据量的一半，`filesystem cache`。
- 拼写纠错：编辑距离
- 简单整合：使用Spring Data Elasticsearch整合，简化交互。通过继承ElasticsearchRepository接口，这样就拥有了一些基本的Elasticsearch数据操作方法，同时可定义一些衍生查询方法。

### Memcached

- 预热、减轻数据库瓶颈，提高服务能力
- nosql= not only sql
- Memcached集群中，每个节点只存储一部分数据。采用二阶段哈希，先由节点列表hash得到存储的节点，在节点中再由内部hash算法，找到真正的数据。
- Memcached不实现冗余机制。不处理容错。无身份认证机制。有多线程模式。基于内存分配器算法，单个item最大1M。单个命令是原子操作，但命令序列不是（依次执行多个命令，比如先get再set）
- 一致性哈希算法：当增删机器时，只有少部分key的路由目标改变。环形空间、虚拟节点
- Memcached与redis的区别：redis支持的数据结构更多、redis支持数据持久化、redis主体是单线程模型，而memcached是多线程模型（可以发挥多核优势）、内存管理方式也有差异

### Redis

- 磁盘格式方面是紧凑的以追加的方式产生的，因为并不需要进行随机访问。

- Redis 主要有以下几种数据类型：

    - String：普通缓存
    - Hash：对象存储
    - List：可用来实现发布/订阅。可当队列用。可以做列表存储，可分页读取
    - Set：可以基于set轻易实现交集、并集、差集的操作。比如关注、点赞、签到、打卡等
    - Sorted Set
    - Redis 除了这 5 种数据类型之外，还有 Bitmap、HyperLogLog、Stream 等
    - Bitmap：通过bitmap, 只需要一个bit位来表示某个元素对应的值或者状态，key就是对应元素本身。登陆、签到、已读/未读，这些是否性质的都可以用。

  [Redis及使用场景](https://mp.weixin.qq.com/s/7ct-mvSIaT3o4-tsMaKRWA)

  Redis的底层是六种数据结构，其中String（字符串）类型的数据底层为简单动态字符串，List（列表）、Hash（哈希）、Set（集合）和 Sorted Set（有序集合）统称为集合类型，其底层分别为以下五种数据结构中的两种，五种数据结构按照查找时间的复杂度分类如下：

  | 数据结构  | 时间复杂度                        |
                        | --------- | --------------------------------- |
  | 哈希表    | O(1)                              |
  | 跳表      | O(logN)                           |
  | 双向链表  | O(N)                              |
  | 压缩链表  | O(N)                              |
  | 整数数组  | O(N)                              |
  | quicklist | 3.0版本开始，List对象底层数据结构 |
  | listpack  | 5.0版本开始，替换压缩链表         |

- Redis五种数据类型底层具体结构

    - 字符串对象编码可以int 、raw或者embstr（后面这俩都是SDS），`如果保存的值为整数值且这个值可以用long类型表示，使用int编码`，其他编码类似。

    - 当list对象可以同时满足以下两个条件时，list对象使用的是ziplist编码：

      `list对象保存的所有字符串元素的长度都小于64字节，list对象保存的元素数量小于512个，`

      不能满足这两个条件的list对象需要使用linkedlist编码。

      3.2开始，list底层都是quicklist。

    - Hash对象的编码可以是ziplist或者hashtable 其中，ziplist底层使用压缩列表实现：

        - 保存同一键值对的两个节点紧靠相邻，键key在前，值vaule在后
        - 先保存的键值对在压缩列表的表头方向，后来在表尾方向

      hashtable底层使用字典实现，Hash对象种的每个键值对都使用一个字典键值对保存：

        - 字典的键为字符串对象，保存键key
        - 字典的值也为字符串对象，保存键值对的值

      当hash对象可以同时满足以下两个条件时，hash对象使用的是ziplist编码：

      `list对象保存的所有字符串元素的长度都小于64字节，list对象保存的元素数量小于512个。`
      不能满足这两个条件的hash对象需要使用hashtable编码

      **Note**：这两个条件的上限值是可以修改的

    - Set对象的编码可以为intset或者hashtable

        - intset编码：使用整数集合作为底层实现，set对象包含的所有元素都被保存在intset整数集合里面
        - hashtable编码：使用字典作为底层实现，字典键key包含一个set元素，而字典的值则都为null

      set对象保存的数据同时满足以下两个条件时，使用intset编码：

      `set对象保存的所有元素都是整数值，set对象保存的元素数量不超过512个`

      不能满足这两个条件的Set对象使用hashtable编码

    - ZSet对象的编码 可以为ziplist或者skiplist

      ziplist编码，每个集合元素使用相邻的两个压缩列表节点保存，一个保存元素成员，一个保存元素的分值，然后根据分数进行从小到大排序。

      skiplist编码的ZSet对象使用了zset结构，包含一个字典和一个跳跃表

      当ZSet对象同时满足以下两个条件时，对象使用ziplist编码

      `有序集合保存的元素数量小于128个，有序集合保存的所有元素的长度都小于64字节`

      不能满足以上两个条件的有序集合对象将使用skiplist编码。

      **Note：**这两个条件的上限值是可以修改的

    - quicklist是一个由ziplist组成的双向链表。但是一个quicklist可以有多个quicklist节点，它很像B树的存储方式。是在redis3.2版本中新加的数据结构，用在列表的底层实现。Redis对于quicklist内部节点的压缩算法，采用的LZF——一种无损压缩算法。

- Redis 服务器是一个事件驱动程序，服务器需要处理两类事件：1. 文件事件; 2. 时间事件

- Redis 基于 Reactor 模式开发了自己的网络事件处理器--文件事件处理器（file event handler）。文件事件处理器使用 I/O 多路复用程序来同时监听多个Socket套接字，并将到达的事件传送给文件事件分派器，分派器会根据套接字目前执行的任务来为套接字关联不同的事件处理器。

  当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。

  **虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字**，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性

- 常用的I/O多路复用模型有：select、poll、epoll。Redis使用epoll做为非阻塞的I/O多路复用的实现

- **Redis6.0 引入多线程主要是为了提高网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。只有网络IO是多线程处理，其他的还是单线程

- 持久化机制：内存快照RDB和追加文件AOF。各有优缺点，另外还可一起使用称为混合持久化

- 优化：Master不要开RDB、可以在Slave开AOF、最好不要所有Slave连同一组Master，可以有的Slave下挂别的Slave

- 键删除策略：定时删除、惰性删除、定期删除。 Redis采用的是惰性删除 + 定期删除

- 淘汰策略：volatile-lru、volatile-random、allkeys-lru、allkeys-random、allkeys-lfu等

- LRU (Least recently used) 最近最少使用，如果数据最近被访问过，那么将来被访问的几率也更高

  LFU (Least frequently used) 最不经常使用，如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小。

- 集群

    - Redis Sentinal 着眼于高可用，在 master 宕机时会自动将 slave 提升为 master，继续提供服务
    - Redis Cluster 着眼于扩展性，在单个 redis 内存不足时，使用 Cluster 进行 分片存储。

- Redis Cluster未使用一致性hash，而是引入了哈希槽的概念，Redis 集群有 16384 个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。

  为什么是16384（2^14）个？

  在redis节点发送心跳包时需要把所有的槽放到这个心跳包里，以便让节点知道当前集群信息，16384=16k，在发送心跳包时使用`char`进行bitmap压缩后是2k（`2 * 8 (8 bit) * 1024(1k) = 16K`），也就是说使用2k的空间创建了16k的槽数。

  虽然使用CRC16算法最多可以分配65535（2^16-1）个槽位，65535=65k，压缩后就是8k（`8 * 8 (8 bit) * 1024(1k) =65K`
  ），也就是说需要需要8k的心跳包，作者认为这样做不太值得；并且一般情况下一个redis集群不会有超过1000个master节点，所以16k的槽位是个比较合适的选择。

  [why redis-cluster use 16384 slots?](https://github.com/redis/redis/issues/2576)

- 事务相关的命令：MULTI、EXEC、DISCARD、WATCH

- Redis用keys指令会阻塞线程，可以考虑使用scan，但有一定的重复概率

- 缓存穿透（不存在的数据，未缓存。通过也缓存及布隆过滤器解决）、缓存击穿（单热key的失效，定时主动更新避免其过期）、缓存雪崩(大批key过期导致、缓存节点挂掉导致，两种情况)。布隆过滤器（支持查和增，不支持删改）

- 分布式锁 setnx

- 读写策略：旁路缓存模式、读写穿透、异步缓存写入。先删除Cache还是先更新DB，当下还不确定，可以先更新DB再延迟双删缓存。

- Redis热点Key问题：本质为流量集中，超过缓存服务的承载。

  解决方法：多个热Key能预估的话将其分到不同的redis上、VM二级缓存（HashMap，可以结合MQ做失效通知，另外还有些不错的解决方案，支持限制总大小、定时过期、内存淘汰等）、备份热Key（读写分离加从节点）、热点数据的发现

- Redis大Key（V很大）。
- Redis集群
    - Redis集群组态的最低要求是必须有三个主节点。
    - Redis集群数据分片（Redis Cluster data sharding），根据一致性Hash，有16384个hash slots，每个节点负责一部分，为了计算给定的key应该在哪个hash slot上，我们简单地用这个key的CRC16值来对16384取模。
    - Redis集群主从模式（Redis Cluster master-slave model），当部分master节点失败了，或者不能够和大多数节点通信的时候，为了保持可用，Redis集群用一个master-slave模式，这样的话每个hash slot就有1到N个副本。
    - Redis集群一致性保证（Redis Cluster consistency guarantees），Redis集群不能保证强一致性。

### Kafka

- 组成：broker、topic、partition、offset、Producer、Consumer、Consumer Group、Zookeeper
- 消息 topic 由多个 partition 组成，且 partition 会均衡分布到不同 broker 上
- Kafka 遵循了一种大部分消息系统共同的传统的设计:producer 将消息推送到 broker，consumer 从 broker 拉取消息。
- Topic 被分成了若干分区，每个分区在同一时间只被一 个 consumer 消费。这意味着每个分区被消费的消息在日志中的位置仅仅是一个简单的整数:offset。这样就很容易标记每个分区消费状态。这样消费状态的跟踪就很简单了。并且consumer可以通过调整offset实现重新消费或跳过几条消息。

### RabbitMQ

- RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。AMQP :Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准。
- 由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶 颈。RabbitMQ 使用信道（Channel）的方式来传输数据。信道是建立在真实的 TCP 连接内的 虚拟连接，且每条 TCP 连接上的信道数量没有限制。
- 架构：Publisher、Exchange、Routing-key、Queue、Binding、Broker、Virtual Host、Channel、Consumer
- 提供推模式和拉模式。默认推模式。
    - Push模式
    - 优点：实时（服务端broker一收到消息就推给consumer）
    - 缺点：容易造成消息堆积（消息保存在服务端broker） 需维护每次传输状态，遇到问题要重试 服务短需要根据消费者能力做流控(比如rabbitmq用qos来限制)
    - Pull模式
        - 优点：保存在消费端，获取方便 传输失败，不需要重试 消费者可根据自身能力来决定流空(因为就是他自己拉取)
        - 缺点：实时性不高，短轮询间隔时间大，实时性就低。有其他优化方式，比如CMQ、kafka(腾讯云的服务)也会采用长轮询优化（长轮询如果拉取失败不会直接断开，而是挂在那里wait,如果服务端有新消息就返回最新数据）

- [5种消息模式](https://www.lwohvye.com/2021/07/09/rabbitmq%e7%9a%845%e7%a7%8d%e6%a0%b8%e5%bf%83%e6%b6%88%e6%81%af%e6%a8%a1%e5%bc%8f/)
- Exchange类型：Direct、Fanout、Topic
- MQ的用途：异步、削峰、解耦
- 结构 几个概念说明:
    - Broker:它提供一种传输服务,它的角色就是维护一条从生产者到消费者的路线，保证数据能按照指定的方式进行传输,
    - Exchange：消息交换机,它指定消息按什么规则,路由到哪个队列。
    - Queue:消息的载体,每个消息都会被投到一个或多个队列。
    - Binding:绑定，它的作用就是把exchange和queue按照路由规则绑定起来.
    - Routing Key:路由关键字,exchange根据这个关键字进行消息投递。
    - vhost:虚拟主机,一个broker里可以有多个vhost，用作不同用户的权限分离。
    - Producer:消息生产者,就是投递消息的程序.
    - Consumer:消息消费者,就是接受消息的程序.
    - Channel:消息通道,在客户端的每个连接里,可建立多个channel.

### Hbase

- 分布式、面向列族的开源数据库。HDFS 为 Hbase 提供可靠的 底层数据存储服务，MapReduce 为 Hbase 提供高性能的计算能力，Zookeeper 为 Hbase 提供 稳定服务和 Failover 机制，因此我们说 Hbase 是一个通过大量廉价的机器解决海量数据的高速存
  储和读取的分布式数据库解决方案。
- HDFS，hadoop distributed filesystem
- Hbase，hadoop nosql database
- 适用场景：海量数据场景，只需要简单的增删改查的支持

### MongoDB

- MongoDB 是由 C++语言编写的，是一个基于分布式文件存储的开源数据库系统。非关系型数据库。
- Mongodb是为快速开发互联网Web应用而构建的数据库系统，其数据模型和持久化策略就是为了构建高读/写吞吐量和高自动灾备伸缩性的系统。
- 简单整合：使用Spring Data Mongodb整合，简化交互。继承MongoRepository接口，这样就拥有了一些基本的Mongodb数据操作方法，同时可定义一些衍生查询方法。

### Spark

- Spark 提供了一个全面、统一的框架用于管理各种有着不同性质(文本数据、图表数据等)的数据集和数据源(批量数据或实时的流数据)的大数据处理的需求。

### 负载均衡

- 负载均衡分类 1）二层负载均衡（mac） 根据OSI模型分的二层负载，一般是用虚拟mac地址方式，外部对虚拟MAC地址请求，负载均衡接收后分配后端实际的MAC地址响应. 2）三层负载均衡（ip） 一般采用虚拟IP地址方式，外部对虚拟的ip地址请求，负载均衡接收后分配后端实际的IP地址响应. (
  即一个ip对一个ip的转发, 端口全放开)
  3）四层负载均衡（tcp） 在三次负载均衡的基础上，即从第四层"传输层"开始, 使用"ip+port"接收请求，再转发到对应的机器。 4）七层负载均衡（http） 从第七层"应用层"开始, 根据虚拟的url或IP，主机名接收请求，再转向相应的处理服务器。

### Hystrix

- 限流、熔断、资源隔离（线程池技术、信号量机制）

### 网关

- 网关的核心功能
    - 动态路由：新开发某个服务，动态把请求路径和服务的映射关系热加载到网关里去；服务增减机器，网关自动热感知
    - 灰度发布
    - 授权认证
    - 性能监控：每个API接口的耗时、成功率、QPS
    - 系统日志
    - 数据缓存
    - 限流熔断
- 几种技术选型：Kong、Gateway、Zuul、Nginx+Lua（OpenResty）、自研网关

### 其他

- 框架不是技术
